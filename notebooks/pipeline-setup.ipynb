{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Redemption model training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import modules as if in based directory, rather than the notebook directory\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import azureml\n",
    "from azureml.core import Workspace, Experiment, Dataset, RunConfiguration, Datastore, Environment\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.data.dataset_consumption_config import DatasetConsumptionConfig\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.widgets import RunDetails\n",
    "    \n",
    "from aml_setup.create_envs import create_env\n",
    "\n",
    "print(\"Azure ML SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(f\"\"\"\n",
    "WS name: {ws.name}\n",
    "Region: {ws.location}\n",
    "Subscription id: {ws.subscription_id}\n",
    "Resource group: {ws.resource_group}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we want to run a test run to debug?\n",
    "debug = True\n",
    "# Do we want to publish the pipeline for future use?\n",
    "publish = True\n",
    "# Given wheel path for AML environment. If none needed use None\n",
    "wheel_path = \"./dist/aml_setup-0.0.1-py3-none-any.whl\"\n",
    "\n",
    "pipeline_name = \"AML-Setup-pipeline\"\n",
    "pipeline_desc = \"Pipeline to test AML Setup\"\n",
    "experiment_name = \"AML-Setup-experiment\"\n",
    "datastore_name_ = \"XXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "\n",
    "print(f\"\"\"\n",
    "debug: {debug}\n",
    "publish: {publish}\n",
    "\n",
    "wheel_path: {wheel_path} \n",
    "\n",
    "pipeline_name: {pipeline_name}\n",
    "pipeline_desc: {pipeline_desc}\n",
    "experiment_name: {experiment_name}\n",
    "datastore_name: {datastore_name_}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline parameters\n",
    "\n",
    "These are parameters that can be passed from ADF into the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_name = PipelineParameter(name=\"datastore_name\", default_value=datastore_name_)\n",
    "datastore = Datastore(workspace=ws, name=datastore_name_)\n",
    "default_ds = Dataset.File.from_files(path=DataPath(datastore, \"error_you_need_to_pass_a_data_path\"), validate=False) \n",
    "\n",
    "test_data_path = PipelineParameter(name=\"test_data_path\", default_value=default_ds)\n",
    "batch_dataset_consumption = DatasetConsumptionConfig(\"test_data_consumption\", test_data_path).as_mount()\n",
    "\n",
    "\n",
    "test_arg = PipelineParameter(name=\"test_arg\", default_value=\"test_string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_dir_path = create_env.create_env_dir(ws,\n",
    "                                                 env_out_dir=\"./envs/\",\n",
    "                                                 version=\"0.0.1\",\n",
    "                                                 overwrite=True,\n",
    "                                                 wheel_path=wheel_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define run steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment.load_from_directory(environment_dir_path)\n",
    "runconfig = RunConfiguration()\n",
    "\n",
    "runconfig.environment = env\n",
    "\n",
    "test_env_step = PythonScriptStep(\n",
    "    name = \"test-env-run\",\n",
    "    source_directory = \"./\",\n",
    "    script_name = \"scripts/test_run.py\",\n",
    "    inputs=[],\n",
    "    arguments = [\n",
    "        '--test_arg', test_arg,\n",
    "    ],\n",
    "    compute_target=\"Standard-D8s-v3\",\n",
    "    runconfig=runconfig,\n",
    "    allow_reuse=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [test_env_step]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline object and validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(workspace=ws, steps=steps)\n",
    "pipeline.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the pipeline against an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For debugging only\n",
    "_test_arg = '[\"This\", \"is\", \"a\", \"test\", \"list\"]'\n",
    "\n",
    "if debug:\n",
    "    # use pipeline_parameters to override default values\n",
    "    pipeline_parameters={\n",
    "        \"test_arg\": _test_arg,\n",
    "    }\n",
    "\n",
    "    pipeline_run = Experiment(ws, experiment_name).submit(pipeline, pipeline_parameters=pipeline_parameters)\n",
    "    RunDetails(pipeline_run).show()\n",
    "    pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if publish:,\n",
    "    pp = pipeline.publish(name=pipeline_name, description=pipeline_desc)\n",
    "    print(pp)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8cc38c4bb8047699636c2195810c420cf741dba35a48faad64f4139883906fdd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('aml': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
